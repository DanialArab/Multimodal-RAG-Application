where €) ~ p(e) and ¢ ~ p(¢). The estimator only depends on samples from p(e) and p(¢) which are obviously not influenced by @, therefore the estimator can be differentiated w.rt. @. The resulting stochastic gradients can be used in conjunction with stochastic optimization methods such as SGD or Adagrad [DHS10]. See algorithm1] for a basic approach to computing stochastic gradients.